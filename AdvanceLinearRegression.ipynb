{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "\n",
    "# Supress Warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Load Data , specify appropriate file path \n",
    "basePath = \"\" #Path where file is located\n",
    "df = pd.read_csv(basePath + \"train.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing and preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns having more than 70% null values as seen from info above\n",
    "df.drop(['Alley','PoolQC','Fence','MiscFeature'],axis =1 , inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle null values for important columns\n",
    "#For LotFrontage, mean and median are close plus there are few outliars, lets replace nulls with median\n",
    "df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].median())\n",
    "#For MasVnrArea , missing values mean , MasVnrType was NA , lets replace with 0\n",
    "df['MasVnrArea'] = df['MasVnrArea'].fillna(0)\n",
    "#For GarageYrBlt , missing values mean , GarageType was NA , lets replace with YearBuilt since no garage was built\n",
    "df['GarageYrBlt'] = df['GarageYrBlt'].fillna(df['YearBuilt'])\n",
    "# For BsmtFinType1 means no basement\n",
    "#Similarly from data dictionary, we know that missing values are NA or None , lets replace them like this for now\n",
    "df['GarageFinish'] = df['GarageFinish'].fillna('NA')\n",
    "df['GarageType'] = df['GarageType'].fillna('NA')\n",
    "df['KitchenQual'] = df['KitchenQual'].fillna('NA')\n",
    "df['BsmtExposure'] = df['BsmtExposure'].fillna('NA')\n",
    "df['BsmtQual'] = df['BsmtQual'].fillna('NA')\n",
    "df['BsmtFinType1'] = df['BsmtFinType1'].fillna('NA')\n",
    "df['MasVnrType'] = df['MasVnrType'].fillna('None')\n",
    "df['FireplaceQu'] = df['FireplaceQu'].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certain columns may have values that are biased towards certain category such that dominant category has > 95% weight. \n",
    "#Lets remove them.\n",
    "for each_column in df.columns:\n",
    "    if df[each_column].dtypes == 'object':\n",
    "        val_cnt_df =  df[each_column].value_counts(normalize = True).to_frame()\n",
    "        print(val_cnt_df)\n",
    "        print('-------------------------------------')\n",
    "        if val_cnt_df.iloc[0,0] > 0.95:\n",
    "            df.drop(each_column,axis =1 , inplace = True)\n",
    "            print('Deleted column : ' , each_column)\n",
    "            print('-------------------------------------') \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlations with respect to response variable SalePrice\n",
    "SalesPriceCorr = df.corr()['SalePrice'].to_frame().sort_values(by='SalePrice',ascending = False)\n",
    "SalesPriceCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns having low correlation with SalePrice , making sure that useful columns are retained ,\n",
    "# while doing this we are more liberal towards negative correlations since we want to buy at lower prices\n",
    "SalesPriceCorr['Cols_Remove'] = np.where(((SalesPriceCorr['SalePrice'] < 0.25) & (SalesPriceCorr['SalePrice'] > -0.05)) ,SalesPriceCorr.index,'KeepThisCol')\n",
    "for eachCol in SalesPriceCorr['Cols_Remove']:\n",
    "    if eachCol != 'KeepThisCol':\n",
    "        df.drop(eachCol,axis =1 , inplace = True)\n",
    "        print(eachCol)\n",
    "SalesPriceCorr = df.corr()['SalePrice'].to_frame()\n",
    "SalesPriceCorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Analysis for Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df.select_dtypes(include=[np.number]).columns\n",
    "for each_numeric_column in df_num:\n",
    "    sns.boxplot(y = each_numeric_column , data = df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eachCol in df.select_dtypes(include=[np.number]).columns:\n",
    "    sns.regplot(y = 'SalePrice' , x = eachCol , data = df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine areas of 2 floors as second floor area is 0 when the floor doesnt exist and remove separate columns for 2 areas\n",
    "df['TotFlrSF'] = df['1stFlrSF'] + df['2ndFlrSF']\n",
    "df.drop(['1stFlrSF','2ndFlrSF'] , axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'LotFrontage', 'Lotarea' have low correlation with target and also they have outliars, \n",
    "# Also from domain, we know that they are related\n",
    "# we will categorize these columns first and see the impact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Funtion for binning \n",
    "def convert_numeric_column_to_categorical_analyze(numeric_column):\n",
    "    q=[0,.25, .5, .75,1]\n",
    "    labels = ['q1','q2','q3','q4']\n",
    "    df['binned_' + numeric_column] = pd.qcut(df[numeric_column], q=q, labels=labels)\n",
    "    print(numeric_column)\n",
    "    df.drop(numeric_column, axis =1 , inplace = True)\n",
    "    df['binned_' + numeric_column] = df['binned_' + numeric_column].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['LotFrontage', 'LotArea']:\n",
    "    convert_numeric_column_to_categorical_analyze(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay median , q1 and q3 values for SalePrice over boxplot for instant readymade insights\n",
    "for each_column in df.columns:\n",
    "    if df[each_column].dtypes == 'object':\n",
    "        grouped = df.loc[:,[each_column, 'SalePrice']].groupby(each_column) .median().sort_values(by='SalePrice')\n",
    "        ax = sns.boxplot(x = each_column , y = 'SalePrice' ,data = df , order = grouped.index)\n",
    "        sns.swarmplot(x = each_column , y = 'SalePrice', data=df, zorder=.5, order = grouped.index)\n",
    "        ax.axhline(df['SalePrice'].median(),linewidth=1,color='b')\n",
    "        ax.axhline(df['SalePrice'].quantile(0.75),linewidth=1,color='r')\n",
    "        ax.axhline(df['SalePrice'].quantile(0.25),linewidth=1,color='g')\n",
    "        ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "        plt.show()\n",
    "        print('-----------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SaleType though useful info. is not helpful in model building and determinant of SalePrice, drop it\n",
    "df.drop('SaleType' , axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exterior1st and Exterior2nd also have many categories and some categories have lesser weights, \n",
    "#lets first combine these categories\n",
    "# And then combine two columns to create a single exterior column and handle nulls\n",
    "df['Exterior1st'] = df['Exterior1st'].map({'VinylSd' : 'VinylSd' , 'HdBoard':'HdBoard' ,'MetalSd' :'MetalSd','Wd Sdng':'Wd Sdng',\n",
    "                                          'Plywood' : 'Modified1' ,'CemntBd': 'Modified1','BrkFace': 'Modified1',\n",
    "                                           'WdShing' : 'Modified2', 'Stucco': 'Modified2' ,'AsbShng': 'Modified2','Stone': 'Modified2'\n",
    "                                           ,'BrkComm' : 'Modified2','ImStucc': 'Modified2','CBlock': 'Modified2', 'AsphShn':'Modified2'\n",
    "                                          })\n",
    "df['Exterior2nd'] = df['Exterior2nd'].map({'VinylSd' : 'VinylSd' , 'HdBoard':'HdBoard' ,'MetalSd' :'MetalSd','Wd Sdng':'Wd Sdng',\n",
    "                                          'Plywood' : 'Modified1' ,'CemntBd': 'Modified1','BrkFace': 'Modified1', \n",
    "                                           'WdShing' : 'Modified2', 'Stucco': 'Modified2' ,'AsbShng': 'Modified2','Stone': 'Modified2'\n",
    "                                           ,'Brk Cmn' : 'Modified2','ImStucc': 'Modified2','CBlock': 'Modified2', 'AsphShn':'Modified2',\n",
    "                                           'Other' : 'Modified2'\n",
    "                                          })\n",
    "\n",
    "df['Exterior'] = np.where(df['Exterior1st'] == df['Exterior2nd'],df['Exterior1st'],df['Exterior1st'] + \"_\" + df['Exterior2nd'])\n",
    "\n",
    "df['Exterior'] = df['Exterior'].fillna('Modified2')\n",
    "df.drop(['Exterior2nd','Exterior1st'],axis =1 , inplace = True)\n",
    "\n",
    "# Further Reduce categories in Exterior and handle nulls\n",
    "df['Exterior'] = df['Exterior'].map({'VinylSd' : 'VinylSd' , 'HdBoard':'HdBoard' ,'MetalSd' :'MetalSd','Wd Sdng':'Wd Sdng',\n",
    "                                          'Plywood' : 'Modified1' ,'Modified2' : 'Modified2'})\n",
    "df['Exterior'] = df['Exterior'].fillna('Modified3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Neighborhood , apply frequency encoding as there are too many categories and small no. of records in each category\n",
    "fe = df.groupby(\"Neighborhood\").size()\n",
    "fe_ = fe/len(df)\n",
    "df[\"Neighborhood\"] = df[\"Neighborhood\"].map(fe_).round(2)\n",
    "df['SalePrice'].corr(df[\"Neighborhood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar exercise for Condition1\n",
    "fe = df.groupby(\"Condition1\").size()\n",
    "fe_ = fe/len(df)\n",
    "df[\"Condition1\"] = df[\"Condition1\"].map(fe_).round(2)\n",
    "df['SalePrice'].corr(df[\"Condition1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bivariate analysis of categorical columns\n",
    "lst_categories = df.select_dtypes(include=['object']).columns\n",
    "for i, eachCategory1 in enumerate(lst_categories):\n",
    "    for j, eachCategory2 in enumerate(lst_categories):\n",
    "        if j<=i :\n",
    "            continue\n",
    "        print('------------------------------------------------------')\n",
    "        ax=df.boxplot(column='SalePrice' ,by=[eachCategory1,eachCategory2] , rot = 90)\n",
    "        ax.axhline(df['SalePrice'].median(),linewidth=1,color='b')\n",
    "        ax.axhline(df['SalePrice'].quantile(0.75),linewidth=1,color='r')\n",
    "        ax.axhline(df['SalePrice'].quantile(0.25),linewidth=1,color='g')\n",
    "        plt.show() \n",
    "        print('------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Some categorical variables especially related to quality looking at the box plot plus data dictionary,\n",
    "#We know that there is ordinality. Lets convert them to numeric maintaining the order.\n",
    "df['ExterQual'] = df['ExterQual'].map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\n",
    "df['BsmtQual'] = df['BsmtQual'].map({'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\n",
    "df['BsmtCond'] = df['BsmtCond'].map({'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5})\n",
    "df['BsmtExposure'] = df['BsmtExposure'].map({'NA':0,'No':1,'Mn':2,'Av':3,'Gd':4})\n",
    "df['HeatingQC'] = df['HeatingQC'].map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\n",
    "df['KitchenQual'] = df['KitchenQual'].map({'Po':0,'Fa':1,'TA':2,'Gd':3,'Ex':4})\n",
    "df['GarageFinish'] = df['GarageFinish'].map({'NA':0,'Unf':1,'RFn':2,'Fin':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now, to make bi/multivariate analysis easier , lets convert categorical objects into numeric objects with label encoding\n",
    "# Being linear regression, this has side effect of introducing ordinality, however this is just intermediate step and \n",
    "#before regression we will one-hot/dummy encode them\n",
    "#Create a list of cetegorical features and maintain it live for ease of handling dummy encoding\n",
    "cat_cols_later_dummy_encoding = []\n",
    "for each_column in df.columns:\n",
    "    if df[each_column].dtypes == 'object':\n",
    "        df[each_column] = df[each_column].astype('category')\n",
    "        df[each_column] = df[each_column].cat.codes\n",
    "        cat_cols_later_dummy_encoding.append(each_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As seen from scatterplot, some numeric variables are also categorical . \n",
    "#Lets see if if they are indeed ordinal and/or if there is need to create dummies from them when no. of categories is small.\n",
    "numericColsWhichCategorical = ['FullBath','HalfBath','KitchenAbvGr','Fireplaces','GarageCars']\n",
    "for each_column in numericColsWhichCategorical:\n",
    "    grouped = df.loc[:,[each_column, 'SalePrice']].groupby(each_column) .median().sort_values(by='SalePrice')\n",
    "    ax = sns.boxplot(x = each_column , y = 'SalePrice' ,data = df , order = grouped.index)\n",
    "    sns.swarmplot(x = each_column , y = 'SalePrice', data=df, zorder=.5, order = grouped.index)\n",
    "    ax.axhline(df['SalePrice'].median(),linewidth=1,color='b')\n",
    "    ax.axhline(df['SalePrice'].quantile(0.75),linewidth=1,color='r')\n",
    "    ax.axhline(df['SalePrice'].quantile(0.25),linewidth=1,color='g')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "    plt.show()\n",
    "    print('-----------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlations with respect to response variable SalePrice \n",
    "# And remove correlations with low correlations with a bit stricter criteria compared to first pass\n",
    "# as this will help us build a fine tuned yet simple model\n",
    "SalesPriceCorr = df.corr()['SalePrice'].to_frame()\n",
    "SalesPriceCorr['Cols_Remove'] = np.where(((SalesPriceCorr['SalePrice'] < 0.4) & (SalesPriceCorr['SalePrice'] > -0.2)) ,SalesPriceCorr.index,'KeepThisCol')\n",
    "for eachCol in SalesPriceCorr['Cols_Remove']:\n",
    "    if eachCol != 'KeepThisCol':\n",
    "        df.drop(eachCol,axis =1 , inplace = True)\n",
    "        if eachCol in numericColsWhichCategorical:\n",
    "            numericColsWhichCategorical.remove(eachCol)\n",
    "        if eachCol in cat_cols_later_dummy_encoding:\n",
    "            cat_cols_later_dummy_encoding.remove(eachCol)\n",
    "        print(eachCol)\n",
    "SalesPriceCorr = df.corr()['SalePrice'].to_frame()\n",
    "SalesPriceCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix for numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (26,30))\n",
    "sns.heatmap(df.corr(),annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observations:\n",
    "# Garage  Type and Neighbourhood have in general weaker correlation with other columns\n",
    "#OveallQuality has good correlation with most of the columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YearBuilt and YearRemodAdd have strong +ve correlation with each other and with SalePrice, \n",
    "# lets create derived variable to make YearRemodAdd as 0 when there is None, that makes the correlation -ve. \n",
    "df['YearRemodAdd'] = np.where (df['YearBuilt'] == df['YearRemodAdd'],0,df['YearRemodAdd'])\n",
    "    #df[['YearBuilt','YearRemodAdd']].max(axis =1)\n",
    "print(df['SalePrice'].corr(df['YearRemodAdd']))\n",
    "print(df['YearBuilt'].corr(df['YearRemodAdd']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#garage year and year build have strong correlation ,hence dropping former as it is less important than later\n",
    "# and also has other correlated columns\n",
    "\n",
    "df.drop(['GarageYrBlt','GarageCars'] , axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets analyze VIF and build a model before dummy variable creation to understand more about multicollinearity \n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = df.columns\n",
    "vif['VIF'] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TotFlrSF has highest VIF and its derived\n",
    "#lets drop \n",
    "df.drop(['TotFlrSF'] , axis =1 , inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets build a raw model first to see at high level if we can further cleanse the data before dummy variable creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test/validation set assuming this will also be tested on separate test data\n",
    "np.random.seed(0)\n",
    "df_train,df_validation = train_test_split(df,train_size =0.8 , test_size = 0.2 , random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standardization\n",
    "scaler = MinMaxScaler()\n",
    "allCols = df_train.columns.values.tolist()\n",
    "df_train[allCols] = scaler.fit_transform(df_train[allCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw = df_train.pop('SalePrice')\n",
    "X_train_raw = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intially use stats models to build a model \n",
    "# where in multicollinearity is handled to an extent and also p values are taken care of \n",
    "x_train_raw_lm = sm.add_constant(X_train_raw)\n",
    "lr_raw = sm.OLS(y_train_raw,x_train_raw_lm).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_raw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use RFE to reduce/prioritize the features\n",
    "lm_raw_rfe = LinearRegression()\n",
    "lm_raw_rfe.fit(X_train_raw, y_train_raw)\n",
    "\n",
    "rfe_raw = RFE(lm_raw_rfe, 15)             # running RFE\n",
    "rfe_raw = rfe_raw.fit(X_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train_raw.columns,rfe_raw.support_,rfe_raw.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a model based on rfe guidance\n",
    "x_train_raw_rfe = X_train_raw[X_train_raw.columns[rfe_raw.support_]]\n",
    "x_train_raw_rfe_lm = sm.add_constant(x_train_raw_rfe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_raw_rfe = sm.OLS(y_train_raw, x_train_raw_rfe_lm).fit()\n",
    "lr_raw_rfe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the p values in shape first by dropping non-significant features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_3 = x_train_raw_rfe.drop('FullBath', axis=1) \n",
    "x_train_3_lm = sm.add_constant(x_train_3)\n",
    "lr_3 = sm.OLS(y_train_raw, x_train_3_lm).fit()\n",
    "lr_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x_train_3.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x_train_3.values, i) for i in range(x_train_3.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a reasonable raw model with optimal variables,create dummy variables to proceed further in final model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lst = list(x_train_3.columns)\n",
    "my_lst.append('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[my_lst]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy encode nominal categorical varaibles \n",
    "for each_column in cat_cols_later_dummy_encoding:\n",
    "    if each_column in df:\n",
    "        dummyCol = pd.get_dummies(df[each_column],prefix = each_column ,drop_first = True)\n",
    "        df = pd.concat([df,dummyCol], axis = 1)\n",
    "        df.drop(each_column,axis =1 , inplace = True)\n",
    "for each_column in numericColsWhichCategorical:\n",
    "    if each_column in df:\n",
    "        dummyCol = pd.get_dummies(df[each_column],prefix = each_column ,drop_first = True)\n",
    "        df = pd.concat([df,dummyCol], axis = 1)\n",
    "        df.drop(each_column,axis =1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split and scaling of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data in training ,validation and testing/validation sets , calling it validation as file given was for training data\n",
    "np.random.seed(0)\n",
    "df_train,df_validation = train_test_split(df,train_size =0.8 , test_size = 0.2 , random_state = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "allCols = df_train.columns.values.tolist()\n",
    "df_train[allCols] = scaler.fit_transform(df_train[allCols])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.pop('SalePrice')\n",
    "X_train = df_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a all variable linear model using statsmodel to make fine tuning easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lm = sm.add_constant(X_train)\n",
    "lr_all = sm.OLS(y_train,x_train_lm).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradually drop variables to arrive at optimal model that does not overfit and\n",
    "# has reasonable multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6 = X_train.drop('Fireplaces_1', axis=1) \n",
    "x_train_6_lm = sm.add_constant(x_train_6)\n",
    "lr_6 = sm.OLS(y_train, x_train_6_lm).fit()\n",
    "lr_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x_train_6.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x_train_6.values, i) for i in range(x_train_6.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6 = x_train_6.drop('BsmtQual', axis=1) \n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x_train_6.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x_train_6.values, i) for i in range(x_train_6.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6 = x_train_6.drop('KitchenQual', axis=1) \n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x_train_6.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x_train_6.values, i) for i in range(x_train_6.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6 = x_train_6.drop('YearBuilt', axis=1) \n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x_train_6.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x_train_6.values, i) for i in range(x_train_6.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6 = x_train_6.drop('OverallQual', axis=1) \n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x_train_6.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x_train_6.values, i) for i in range(x_train_6.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6_lm = sm.add_constant(x_train_6)\n",
    "lr_6 = sm.OLS(y_train, x_train_6_lm).fit()\n",
    "lr_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6 = x_train_6.drop('ExterQual', axis=1) \n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x_train_6.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x_train_6.values, i) for i in range(x_train_6.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6_lm = sm.add_constant(x_train_6)\n",
    "lr_6 = sm.OLS(y_train, x_train_6_lm).fit()\n",
    "lr_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6 = x_train_6.drop('binned_LotArea_2', axis=1) \n",
    "x_train_6_lm = sm.add_constant(x_train_6)\n",
    "lr_6 = sm.OLS(y_train, x_train_6_lm).fit()\n",
    "lr_6.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6 = x_train_6.drop('binned_LotArea_1', axis=1) \n",
    "x_train_6_lm = sm.add_constant(x_train_6)\n",
    "lr_6 = sm.OLS(y_train, x_train_6_lm).fit()\n",
    "lr_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x_train_6.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x_train_6.values, i) for i in range(x_train_6.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6 = x_train_6.drop('YearRemodAdd', axis=1) #['binned_LotArea_3','Fireplaces_2','Fireplaces_3']\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x_train_6.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x_train_6.values, i) for i in range(x_train_6.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6_lm = sm.add_constant(x_train_6)\n",
    "lr_6 = sm.OLS(y_train, x_train_6_lm).fit()\n",
    "lr_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_6 = x_train_6.drop('binned_LotArea_3', axis=1)\n",
    "x_train_6_lm = sm.add_constant(x_train_6)\n",
    "lr_6 = sm.OLS(y_train, x_train_6_lm).fit()\n",
    "lr_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['Features'] = x_train_6.columns\n",
    "vif['VIF'] = [variance_inflation_factor(x_train_6.values, i) for i in range(x_train_6.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So we have a stable model now, lets validate assumptions of linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lr_6.predict(x_train_6_lm)\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_pred), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \n",
    "plt.xlabel('Errors', fontsize = 18)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for patterns in residuals\n",
    "sns.scatterplot(x_train_6.index,y_train - y_train_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization and model evaluation and comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before regularization, Just creating same model using sklearn for easier comparisons\n",
    "reg = LinearRegression() \n",
    "reg.fit(x_train_6,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coefficients and intercept\n",
    "print(reg.intercept_)\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions on validation data \n",
    "df_validation[allCols] = scaler.transform(df_validation[allCols])\n",
    "y_validation = df_validation.pop('SalePrice')\n",
    "X_validation = df_validation[x_train_6.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_effectiveness(y_train,y_pred_train,y_validation,y_pred_validation,explained_variance = 0):\n",
    "    metric = []\n",
    "    r2_train_lr = r2_score(y_train, y_pred_train)\n",
    "    print(r2_train_lr)\n",
    "    metric.append(r2_train_lr)\n",
    "\n",
    "    r2_test_lr = r2_score(y_validation, y_pred_validation)\n",
    "    print(r2_test_lr)\n",
    "    metric.append(r2_test_lr)\n",
    "\n",
    "    rss1_lr = np.sum(np.square(y_train - y_pred_train))\n",
    "    print(rss1_lr)\n",
    "    metric.append(rss1_lr)\n",
    "\n",
    "    rss2_lr = np.sum(np.square(y_validation - y_pred_validation))\n",
    "    print(rss2_lr)\n",
    "    metric.append(rss2_lr)\n",
    "\n",
    "    mse_train_lr = mean_squared_error(y_train, y_pred_train)\n",
    "    print(mse_train_lr)\n",
    "    metric.append(mse_train_lr**0.5)\n",
    "\n",
    "    mse_test_lr = mean_squared_error(y_validation, y_pred_validation)\n",
    "    print(mse_test_lr)\n",
    "    metric.append(mse_test_lr**0.5)\n",
    "    \n",
    "    print(explained_variance)\n",
    "    metric.append(explained_variance)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = reg.predict(x_train_6)\n",
    "y_pred_validation = reg.predict(X_validation)\n",
    "metricReg = model_effectiveness(y_train,y_pred_train,y_validation,y_pred_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets plot results and see if predictions are reasonable\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_validation, y_pred_validation)\n",
    "fig.suptitle('y_validation vs y_pred_validation', fontsize = 20)              # Plot heading \n",
    "plt.xlabel('y_validation', fontsize = 18)                          # X-label\n",
    "plt.ylabel('y_pred_validation', fontsize = 16)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge and Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runRegularization(estimator,scoring,folds):\n",
    "    model_cv = GridSearchCV(estimator = estimator, \n",
    "                    param_grid = params, \n",
    "                    scoring= 'explained_variance',  \n",
    "                    cv = folds, \n",
    "                    return_train_score=True,\n",
    "                    verbose = 1) \n",
    "    return(model_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of alphas to tune - if value too high it will lead to underfitting, if it is too low, \n",
    "# it will not handle the overfitting\n",
    "# use explained_variance as it is bounded\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "\n",
    "ridge1 = Ridge()\n",
    "ridge1_model_cv_explained_variance = runRegularization(ridge1,'explained_variance',5)\n",
    "    \n",
    "ridge1_model_cv_explained_variance.fit(x_train_6, y_train) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Ridge model for alpha = 3 and printing coefficients which have been penalised\n",
    "ridge1 = Ridge(alpha=ridge1_model_cv_explained_variance.best_params_['alpha'])\n",
    "ridge1.fit(x_train_6, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = ridge1.predict(x_train_6)\n",
    "y_pred_validation = ridge1.predict(X_validation)\n",
    "\n",
    "metricRidge1 = model_effectiveness(y_train,y_pred_train,y_validation,y_pred_validation,explained_variance_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "\n",
    "ridge2 = Ridge()\n",
    "ridge2_model_cv_neg_mean_absolute_error = runRegularization(ridge2,'neg_mean_absolute_error',10)\n",
    "    \n",
    "ridge2_model_cv_neg_mean_absolute_error.fit(x_train_6, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build another ridge model with alpha double than previous model\n",
    "ridge2 = Ridge(alpha=2*ridge2_model_cv_neg_mean_absolute_error.best_params_['alpha'])\n",
    "ridge2.fit(x_train_6, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = ridge2.predict(x_train_6)\n",
    "y_pred_validation = ridge2.predict(X_validation)\n",
    "\n",
    "metricridge2 = model_effectiveness(y_train,y_pred_train,y_validation,y_pred_validation,explained_variance_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {'alpha': [0.000008,0.0001,0.0006, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "# cross validation\n",
    "lasso1 = Lasso()\n",
    "lasso1_model_cv_explained_variance = runRegularization(lasso1,'explained_variance',5)\n",
    "    \n",
    "lasso1_model_cv_explained_variance.fit(x_train_6, y_train)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso1 = Lasso(alpha=lasso1_model_cv_explained_variance.best_params_['alpha'])\n",
    "lasso1.fit(x_train_6, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = lasso1.predict(x_train_6)\n",
    "y_pred_validation = lasso1.predict(X_validation)\n",
    "\n",
    "metricLasso1 = model_effectiveness(y_train,y_pred_train,y_validation,y_pred_validation,explained_variance_score(y_train,y_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model with double alpha\n",
    "lasso2 = Lasso(alpha=2*lasso1_model_cv_explained_variance.best_params_['alpha'])\n",
    "lasso2.fit(x_train_6, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = lasso2.predict(x_train_6)\n",
    "y_pred_validation = lasso2.predict(X_validation)\n",
    "\n",
    "metricLasso2 = model_effectiveness(y_train,y_pred_train,y_validation,y_pred_validation,explained_variance_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table which contain all the metrics for\n",
    "# linear model , regularized models and model using twice regularization alpha\n",
    "\n",
    "lr_table = {'Metric': ['R2 Score (Train)','R2 Score (Test)','RSS (Train)','RSS (Test)',\n",
    "                       'MSE (Train)','MSE (Test)','ExplainedVariance'], \n",
    "        'Linear Regression': metricReg\n",
    "        }\n",
    "\n",
    "lr_metric = pd.DataFrame(lr_table ,columns = ['Metric', 'Linear Regression'] )\n",
    "\n",
    "rg1_metric = pd.Series(metricRidge1, name = 'Ridge1')\n",
    "rg2_metric = pd.Series(metricridge2, name = 'Ridge2')\n",
    "ls1_metric = pd.Series(metricLasso1, name = 'Lasso1')\n",
    "ls2_metric = pd.Series(metricLasso2, name = 'Lasso2')\n",
    "\n",
    "\n",
    "final_metric = pd.concat([lr_metric, rg1_metric, rg2_metric, ls1_metric, ls2_metric], axis = 1)\n",
    "\n",
    "final_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Among these , the model Ridge1 looks optimal as R2 is more stable and RSS/MSE slightly smaller, \n",
    "# otherwise Ridge1 and Lasso1 are comparable\n",
    "#Also doubling alpha slightly reduces effectiveness of regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataframe for instant inght into regularization shrinkage and comparison\n",
    "betas = pd.DataFrame(index=x_train_6.columns)\n",
    "betas.rows = x_train_6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas['Linear'] = reg.coef_\n",
    "betas['Ridge1'] = ridge1.coef_\n",
    "betas['Lasso1'] = lasso1.coef_\n",
    "betas['Ridge2'] = ridge2.coef_\n",
    "betas['Lasso2'] = lasso2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.sort_values(by='Ridge1', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print intercept\n",
    "print('Linear  ' , reg.intercept_)\n",
    "print('Ridge1  ' , ridge1.intercept_)\n",
    "print('Lasso1  ' , lasso1.intercept_)\n",
    "print('Ridge2  ' , ridge2.intercept_)\n",
    "print('Lasso2  ' , lasso2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our choice is  Ridge (model named Ridge 1) however for questions build another model \n",
    "# Its possible that this might overfit slightly, lets see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [0.000008,0.0001,0.0006, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "# cross validation\n",
    "lasso_all = Lasso()\n",
    "lasso_all_model_cv_explained_variance = runRegularization(lasso_all,'explained_variance',5)\n",
    "    \n",
    "lasso_all_model_cv_explained_variance.fit(X_train, y_train)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_all = Lasso(alpha=lasso_all_model_cv_explained_variance.best_params_['alpha'])\n",
    "lasso_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = df_validation\n",
    "y_pred_train = lasso_all.predict(X_train)\n",
    "y_pred_validation = lasso_all.predict(x_all)\n",
    "\n",
    "metricLasso_all = model_effectiveness(y_train,y_pred_train,y_validation,y_pred_validation,explained_variance_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_all = pd.DataFrame(index=X_train.columns)\n",
    "betas_all.rows = X_train.columns\n",
    "betas_all['Lasso_all'] = lasso_all.coef_\n",
    "betas_all.sort_values(by='Lasso_all', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train.drop(['GrLivArea','OverallQual','TotalBsmtSF','MasVnrArea','GarageArea'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': [0.000008,0.0001,0.0006, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "# cross validation\n",
    "lasso_all_drop_top5 = Lasso()\n",
    "lasso_all_drop_top5_model_cv_explained_variance = runRegularization(lasso_all_drop_top5,'explained_variance',5)\n",
    "    \n",
    "lasso_all_drop_top5_model_cv_explained_variance.fit(X_train_new, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_all_drop_top5 = Lasso(alpha=lasso_all_drop_top5_model_cv_explained_variance.best_params_['alpha'])\n",
    "lasso_all_drop_top5.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_drop_top5 = df_validation.drop(['GrLivArea','OverallQual','TotalBsmtSF','MasVnrArea','GarageArea'],axis =1)\n",
    "y_pred_train = lasso_all_drop_top5.predict(X_train_new)\n",
    "y_pred_validation = lasso_all_drop_top5.predict(x_all_drop_top5)\n",
    "\n",
    "metricLasso_all_drop_top5 = model_effectiveness(y_train,y_pred_train,y_validation,y_pred_validation,explained_variance_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_all_drop_top5 = pd.DataFrame(index=X_train_new.columns)\n",
    "betas_all_drop_top5.rows = X_train_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_all_drop_top5['Lasso_all_drop_top5'] = lasso_all_drop_top5.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_all_drop_top5.sort_values(by='Lasso_all_drop_top5', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"End of Regression , thanks Upgrade and  IITB for nice assignment, it was good learning\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
